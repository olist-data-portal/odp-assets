---
alwaysApply: true
---

# プロジェクト概要

このプロジェクトは、DagsterでオーケストレーションするデータパイプラインのアプリケーションをdbtとPythonで作成します。

## データパイプラインの構成

以下の3つのステップで構成されます：

1. **APIからGCSへのデータ取得**: 外部APIからデータを取得し、GCS（データレイク）に保存
2. **GCSからBigQueryへのロード**: GCSのデータをBigQuery（データウェアハウス）にロード
3. **dbtでのモデル構築**: BigQueryのデータをdbtで変換・モデル化

## プロジェクト情報

- **GCPプロジェクトID**: `olist-data-portal`
- **リソースプレフィックス**: `odp`

## 環境

- **local環境**: ローカル開発環境（Docker環境を使用）
- **dev環境**: 開発環境（GKE上で実行）
  - **重要**: `feature-`ブランチがリモートにプッシュされた時にCI/CDでdev環境に反映
- **prd環境**: 本番環境（GKE上で実行）
  - **重要**: `main`ブランチにマージされた時にCI/CDでprd環境に反映

## インフラとの関係

**インフラリポジトリで管理**: GKE、Cloud SQL、サービスアカウント、VPC Connector、Cloud BuildサービスアカウントへのIAMロール付与等

**このアプリケーションリポジトリで管理**:
- Dagsterのアセット定義（Python）
- dbtプロジェクト（dbtモデル定義）
- Cloud Buildの設定（`cloudbuild_ci.yaml`、`cloudbuild_cd.yaml`）
- Kubernetes DeploymentとJobの定義（`deployments/`ディレクトリ配下）
- データパイプライン用GCPリソース（GCSバケット、task/executionサービスアカウントへのIAMロール付与）
